\documentclass{article}

\usepackage[margin=1in]{geometry}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{bchart}
\usepackage{braket}
\usepackage{bytefield}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{newclude}
\usepackage{parskip}
\usepackage{pgfplots}
\usepackage[group-separator={,}]{siunitx}
\usepackage{subfig}
\usepackage{titling}

\newcommand{\colorbitbox}[3]{%
  \rlap{\bitbox{#2}{\color{#1}\rule{\width}{\height}}}\bitbox{#2}{#3}}

\begin{document}

\title{\vspace{-1cm}AI Project 2: Genetic Algorithm}
\author{Roy Howie}
\date{February 27, 2017}
\maketitle

\section{The Genetic Algorithm}
  The Genetic Algorithm is a stochastic, heuristic-based algorithm which draws
  its inspiration from the Darwinian principle of natural selection. It aims to
  generate high-quality but not necessarily maximal solutions to optimization
  and search problems.

  The algorithm requires an initial population and a fitness function which it
  seeks to maximize. The initial population is usually a collection of
  individuals which have each been given a random genetic makeup. The algorithm
  is then able to efficiently search through extremely large domains via three
  search operators:
  \begin{itemize}
    \renewcommand\labelitemi{}
    \item{
      \textbf{Survival.} This determines whether a given individual lives on to
      the next generation.
    }
    \item{
      \textbf{Recombination.} Individuals selected for survival are mated and
      their genetic compositions mixed.
    }
    \item{
      \textbf{Mutation.} A chromosome is occasionally incorrectly copied when
      passed onto the next generation.
    }
  \end{itemize}
  The application of these three search operators to a population is the act of
  moving from one generation to the next.

  Note that each of these three operators can be customized for whichever domain
  is under consideration.

  For example, the \textbf{survival} operator could be changed to always include
  the top quintile in its selection. The \textbf{recombination} operator could
  randomly select the offsprings' genes from each parent or it could ensure an
  even split. Instead of remaining constant, the \textbf{mutation} rate can be
  intensified or lessened over time. The possibilities are endless.

  Last, the algorithm requires a termination criterion, such as having
  attained a maximal level of fitness within a population or having run for a
  given number of generations. This termination criterion must take into account
  the possibility of \textbf{premature degeneration}. This is when a population
  devolves into a small set of similar individuals and is thus no longer capable
  of genetic diversity through mating. To overcome this affliction, the mutation
  rate may be momentarily increased to great effect.

\section{Implementation}
  \subsection{Fitness Function}
    The fitness function we sought to maximize was
    $$
      f(x)= 12 +
      10\cos\left\{
        \ln\left[0.1 + \left(
          \frac{x-{10}^5}{1000}
        \right)^2
        \right]
      \right\}
      -2\sin\left(
        \frac{x-{10}^5}{1000}
      \right)
    $$
    for all integer $x$. Note $\inf{f}=0$ and $\sup{f}=24$.
    \include*{function}

  \subsection{Individuals}\label{individual-ranges}
    Individuals are represented via a binary string of 20 bits. Therefore, the
    range of individuals was all integers between $0$ and $2^{20}-1$.

  \subsection{Search Operators}
    \subsubsection{Survival}
      Individuals were selected for the next generation using a weighted
      probability distribution.

      For example, denote the current generation as $P$ and let it consist
      of a list of numbers in the range specified in \ref{individual-ranges}.
      Let $F$ be the corresponding array of fitness values of the members of
      $P$ and let $C$ be the cumulative sum of $F$.
      \include*{table1}

      If $k$ individuals are desired for the next generation, then pick $k$
      random numbers $\set{r_1,r_2,\cdots,r_k}$ between $0$ and $\max(C)=56.31$.
      Next, for each $i$, find the least $j$ such that $r_i < C[j+1]$ and
      include the individual at index $j$ of $P$ in the next generation.

      Note that the same individual may be selected multiple times to be
      included in the next generation, unlike in real life. Indeed, this is the
      intended behavior: that individuals with higher fitness values shall have
      a greater chance of surviving and will thus appear in larger number in the
      generations to come.

    \subsubsection{Recombination}
      The 2-point crossover method was used for mating. As individuals were
      selected for survival, they were put into mother-father pairs. Each
      mother and father pair was cloned into a daughter and a son, respectively.
      Then, two random indices $a<b$ were chosen and the binary digits between
      these indices were then ``swapped'' between the daughter and son's
      chromosomes.

      For example, suppose the mother could be represented with the
      sequence of binary digits $m_1\cdots m_k$ and the father by $f_1\cdots
      f_k$. Choose $0<a<b\leq k$. Then the daughter would be $m_1\cdots m_{a-1}
      f_a\cdots f_bm_{b+1}\cdots m_k$ and the son would be $f_1\cdots f_{a-1}m_a
      \cdots m_bf_{b+1}\cdots f_k$. This is best seen as illustrated in Figure
      \ref{recomb}.
      \include*{recombination}

    \subsubsection{Mutation}
      After mother-father pairs are recombined into daughter-son pairs, each
      child is given a 1-in-100 chance to mutate. If selected for mutation,
      each digit in the child's binary representation is given a 1-in-25
      chance of flipping, i.e., \texttt{BITWISE NOT}.

  \subsection{Termination Criterion}\label{termination-criterion}
    The algorithm was run until at least one of the following became true:
    \begin{itemize}
      \renewcommand\labelitemi{$\star$}
      \item{
        An individual had attained a fitness value greater than \num{23.97}.
      }
      \item{
        The algorithm had searched for \num{100000} generations.
      }
      \item{
        The max fitness level of the past \num{1000} generations had remained
        constant.
      }
    \end{itemize}

\section{Objectives}
  \begin{itemize}
    \renewcommand\labelitemi{$\star$}
    \item{
      Understand how the average and max fitness of a population evolve over
      time.
    }
    \item{
      Determine how the mutation rate affects a population's fitness over time.
    }
    \item{
      Determine the relationship between population size, number of calls to the
      fitness function (total number of individuals), and the number of
      generations needed to find a solution.
    }
  \end{itemize}

\section{Results}
  \include*{gen-v-pop}
  \include*{individuals-v-pop}
  \include*{gen-vs-individuals}
  \include*{indiv-mut-rate-avg}
  \clearpage
  \include*{indiv-mut-rate-max}


\section{Discussion}
  \subsection{On the Best Approach}
    As can be seen in Figures \ref{gen-vs-pop} through \ref{avg-max-fitness},
    the ideal implementation of the Genetic Algorithm often consisted of a
    larger initial population. Indeed, as can be observed in Figure
    \ref{gen-vs-individuals}, the lower the number of generations needed to find
    a solution, the fewer individuals observed. This is intuitive and reveals a
    subtle but important notion: a large initial investment (large population)
    resulted in a better payoff long-term (less computation).

    Furthermore, a mutation rate of less than 1-in-100 was observed to be ideal.

  \subsection{On Premature Degeneration}
    Premature degeneration did not occur very often. However, to prevent the
    algorithm from looping indefinitely, as explained in Section
    \ref{termination-criterion}, we only allowed the algorithm to run for less
    than \num{100000} generations.

    In addition, we wanted the max fitness of a
    population to climb somewhat monotonically over time. Thus, if the max
    fitness of a population did not increase for \num{1000} generations in a
    row, the algorithm was terminated.

    Even when premature degeneration did occur, the algorithm had often already
    found a solution rather close to the one we deemed optimal, i.e., a max
    fitness level of at least \num{23.97}.

  \subsection{On Improvements}
    The algorithm was implemented in JavaScript. While the \texttt{v8 JavaScript
    Engine} developed under the Chromium Project and used by \texttt{node.js}
    makes JavaScript rather fast, it is often still no match for \texttt{C++}.
    Furthermore, maximizing a function is not necessarily computationally
    expensive. Indeed, as will be seen in Section \ref{BONUS}, a \texttt{C++}
    implemenation would have allowed us to natively hook into the \texttt{gd}
    Graphics Library and more quickly process images.

\section{Bonus: Genetic Programming \& Hill-Climbing Search}\label{BONUS}
  As a bonus, we decided to mix hill-climbing search and genetic programming to
  see if the computer could ``paint'' someone. Namely, the author's girlfriend.
  \include*{bonus-fig}

\end{document}
